---
title: "Case Study 1"
author: "Alex Martinez"
date: "2024-09-10"
output: pdf_document
---

```{r libraries, include=FALSE}
#| echo: false
library(caret)
library(here)
library(lattice)
library(ggplot2)
library(logistf)
library(MASS)
library(tidyverse)
library(corrplot)
library(car)
library(ROCR)
library(dplyr)
```

```{r Loading Data, warning=FALSE}
#| echo: false
getwd() #open R project file to have the same file path
df1 = read.csv2("Data/bank-additional.csv") # Reading the csv from the location above

```

## Data Structure

```{r Data Structure}
#| echo: false
str(df1) #probably remove from final paper
```

## Data Cleanup

```{r Data Cleanup}
#| echo: false
#change y into factor 
df1$y<-as.factor(df1$y)
df1$job<- as.factor(df1$job)
df1$marital <- as.factor(df1$marital)
df1$education <- as.factor(df1$education)
df1$default <- as.factor(df1$default)
df1$housing<- as.factor(df1$housing)
df1$loan <- as.factor(df1$loan)
df1$contact <- as.factor(df1$contact)
df1$month <- as.factor(df1$month)
df1$day_of_week <- as.factor(df1$day_of_week)
df1$poutcome <- as.factor(df1$poutcome)
df1$emp.var.rate <- as.numeric(df1$emp.var.rate)
df1$cons.price.idx <- as.numeric(df1$cons.price.idx)
df1$cons.conf.idx <- as.numeric(df1$cons.conf.idx)
df1$euribor3m <- as.numeric(df1$euribor3m)
df1$nr.employed <- as.integer(df1$nr.employed)
unique(df1$previous)
unique(df1$pdays)
df1$y_int <- ifelse(df1$y == 'yes', 1, 0)
df1$ppdays_ind <- ifelse(df1$pdays == 999, 0, 1)
df1$married_ind <- ifelse(df1$marital == 'married', 1, 0)


#Pdays - make it an indicator of not/yes
#duration - amt of time you have them, so same as Y 

```

## Data Exploration

### Correlation

```{r Correlation}
#| echo: false
# is there high correlation in any of our numeric variables
df_num <- dplyr::select_if(df1, is.numeric)
M = cor(df_num)
#looks like there is higher correlation between pdays and previous but it is under .6 
corrplot(M, method = c("color"))

```

### Unbalanced Dataset

```{r Unbalanced Dataset}
#| echo: false
#data is unbalanced 3.6k no, 451 yes
summary(df1$y)

```

### Distribution (Numeric Variables)

```{r Distribution of Numerical Variables}
#| echo: false
#testing variables
##we can discuss this ones during class
bank_long = df1 %>% 
  dplyr::select(age, campaign, previous, emp.var.rate, cons.price.idx, 
                cons.conf.idx, euribor3m, nr.employed) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

#facet view
ggplot(bank_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "gray", color = "black") +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Distribution of Variables", x = NULL, y = "Frequency") +
  theme(strip.text = element_text(face = "bold"))

#normalizing the data
df_norm <- df1
numeric_columns <- sapply(df_norm, is.numeric)
df_norm[numeric_columns] <- scale(df_norm[numeric_columns])

bank_long_norm = df_norm %>% 
  dplyr::select(age, campaign, previous, emp.var.rate, cons.price.idx, 
                cons.conf.idx, euribor3m, nr.employed) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

ggplot(bank_long_norm, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "gray", color = "black") +
  facet_wrap(~ Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Distribution of Variables", x = NULL, y = "Frequency") +
  theme(strip.text = element_text(face = "bold"))
```

### Distribution (Categorical Variables)

```{r Distribution of Categorical Variables}
#| echo: false
#testing variables
##we can discuss this ones during class
bank_long_cat = df1 %>% 
  dplyr::select(job, marital, education, default, housing, loan, contact, poutcome) %>% 
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

#facet view
ggplot(bank_long_cat, aes(x = Value)) +
  geom_bar(fill = "gray", color = "black") +
  facet_wrap(~ Variable, scales = "free", ncol = 3) +
  theme_minimal() +
  labs(title = "Distribution of Categorical Variables", x = NULL, y = "Count") +
  theme(strip.text = element_text(face = "bold"), axis.text.x = element_text(angle = 45, hjust = 1))

```

# Results:

*Presents and discusses the results from model(s). Discusses relationships between covariates and response, if possible, and provides deep insights behind relationships in the context of the application.*

# Conclusions:

*Concludes with a summary of the aim and results. Discusses alternative methods that can be used.*

```{r Variable Selection}
#keep variables I want for Modeling
df2 <- df1 %>% select(age,job, married_ind, education, default, housing, loan, contact, campaign, 
                      ppdays_ind, previous, poutcome, emp.var.rate, cons.price.idx, cons.conf.idx, 
                      euribor3m, nr.employed, y, y_int)

# selecting for center and scaled data
df2_norm <- df_norm %>% select(age,job, married_ind, education, default, housing, loan, contact, campaign, 
                      ppdays_ind, previous, poutcome, emp.var.rate, cons.price.idx, cons.conf.idx, 
                      euribor3m, nr.employed, y, y_int)
```

```{r Balancing Dataset}
# since data is unbalanced we should take a more balanced sample
set.seed(42) 
df_y_y = df2 %>% filter(y == "yes")
df_y_n = df2 %>% filter(y == "no")
sample_y = sample_n(df_y_n, nrow(df_y_y))
df_bal = rbind(df_y_y,sample_y)
summary(df_bal$y)
```

```{r Data Splitting}
# test and train split
df_bal_split <- sample(nrow(df_bal),0.8*nrow(df_bal),replace = F) # Setting training sample to be 80% of the data
df_train <- df_bal[df_bal_split,]
df_test <- df_bal[-df_bal_split,]
```

```{r model building}
# creating binary numeric variable for linear model
str(df2)

# first exploring with backwards step selection on lm with full data
lm1 <- lm(y_int ~ . -y, data = df_train)
summary(lm1)

lm1_step <- step(lm1, direction = "backward")
summary(lm1_step)

# final lm model base off of step 
lmf <- lm(y_int ~ age + contact + campaign + poutcome + emp.var.rate + 
    cons.price.idx + cons.conf.idx, data = df_train)
#summary(lmf)

vif(lmf) # confirm there is no co linearity 
# R- Squared is very small at 27% but is expectedc since y is binomial


### LETS TRY SAME TECHNIQUE BUT WITH LOGISTIC MODEL
#glm model
glm1 <- glm(y_int ~ . -y, data = df_train, family = binomial) #Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
summary(glm1)

# using backwards Step Selection
glm_step = step(glm1, direction = "backward") # stepwise backward elim.
summary(glm_step)

glmf <- glm(formula = y_int ~ age + contact + campaign + previous + poutcome + 
    emp.var.rate + cons.price.idx + cons.conf.idx, family = binomial, 
    data = df_train)
summary(glmf)

vif(glmf) # no colinearity detected

# Predict the probability on TEST - cutoff 0.5
df_test$PredProb <- predict.glm(glmf, newdata = df_test, type = 'response')

#create Prediction Indicators for y
df_test$Pred_Y <- ifelse(df_test$PredProb >= 0.5, 1, 0)

caret::confusionMatrix(as.factor(df_test$y_int),as.factor(df_test$Pred_Y), positive = '1') #this function and package auto computes a lot of the metrics
# accuracy: 74%
# sens: 80%
# Spec: 70%

plot(glmf)


##DETER4MINING BEST THRESHOLD FOR BEST SENSITIVITY

# Predict the probability (p) of x23strat
glmftest <- glm(formula = y_int ~ age + contact + campaign + previous + poutcome + 
    emp.var.rate + cons.price.idx + cons.conf.idx, family = binomial, 
    data = df_test)
probabilities <- predict(glmftest, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)

#### end of default cutoff of 0.5
#### optimal cutoff

#ROC Curve and AUC
pred <- prediction(probabilities,df_test$y_int) 
pred
#Predicted Probability and True Classification

# area under curve
auc <- round(as.numeric(performance(pred, measure = "auc")@y.values),3)
auc

#plotting the ROC curve and computing AUC
perf <- performance(pred, "tpr","fpr")
plot(perf,colorize = T, main = "ROC Curve")
text(0.5,0.5, paste("AUC:", auc))

# computing threshold for cutoff to best trade off sensitivity and specificity
#first sensitivity
plot(unlist(performance(pred, "sens")@x.values), unlist(performance(pred, "sens")@y.values), 
     type="l", lwd=2, 
     ylab="Sensitivity", xlab="Cutoff", main = paste("Maximized Cutoff\n","AUC: ",auc))

par(new=TRUE) # plot another line in same plot

#second specificity
plot(unlist(performance(pred, "spec")@x.values), unlist(performance(pred, "spec")@y.values), 
     type="l", lwd=2, col='red', ylab="", xlab="")
axis(4, at=seq(0,1,0.2)) #specificity axis labels
mtext("Specificity",side=4, col='red')

#find where the lines intersect
min.diff <-which.min(abs(unlist(performance(pred, "sens")@y.values) - unlist(performance(pred, "spec")@y.values)))
min.x<-unlist(performance(pred, "sens")@x.values)[min.diff]
min.y<-unlist(performance(pred, "spec")@y.values)[min.diff]
optimal <-min.x #this is the optimal points to best trade off sensitivity and specificity

abline(h = min.y, lty = 3)
abline(v = min.x, lty = 3)
text(min.x,0,paste("optimal threshold=",round(optimal,2)), pos = 3)





##OPTIMAL CUTOFF FOR BEST SENSITIVITY and specificity
#create Prediction Indicators for y
df_test$Pred_Y_best <- ifelse(df_test$PredProb >= 0.46, 1, 0)
caret::confusionMatrix(as.factor(df_test$y_int),as.factor(df_test$Pred_Y_best), positive = '1') #this function and package auto computes a lot of the metrics
# accuracy: 73%
# sens: 77%
# Spec: 70%


## best sensitivity
df_test$Pred_Y_sens <- ifelse(df_test$PredProb >= 0.3, 1, 0)
caret::confusionMatrix(as.factor(df_test$Pred_Y_sens), as.factor(df_test$y_int), positive = '1') #this function and package auto computes a lot of the metrics
# accuracy: 60%
# sens: 85%
# Spec: 34%



```

# REPORTING OUTLINE/UPDATES

# Bank Marketing Case Study

# Executive Summary:

*Brief introduction of problem. Summarizes key findings. Summarizes insights behind key findings.*

# Our Problem:

*Clear description of the problem, from an application and theoretical point of view. Outlines the report.*

The primary problem this case study addresses is identifying the variables that significantly influence whether customers will subscribe ('yes') or not ('no') to a bank term deposit product.
From a theoretical perspective, the study aims to determine which predictor variables significantly impact the likelihood of a customer subscribing to a bank term deposit, using statistical models such as logistic and linear regression to analyze the data

# Literature Review:

*Discusses and cites existing works in the theoretical and application realm.*

# Methods:

*Discusses types of variables, sample size, and sampling techniques (if any). Discusses the model(s) and its assumptions and limitations.*

Type of Variables:
When loading the data, the majority of the variables were imported as character variables. We had to adjust them to match the information given to us. After making the necessary changes, we ended up with factors, numeric, and integer variables. We also created dummy variables, which we will discuss later.

Sample Size and Techniques:
The sample size is 4,119 with 21 variables. Due to the sample being unbalanced towards a "no" answer on the y variable, we resampled the data. This process reduced the 4,119 samples to slightly over 900, which we used to train our model.

Models, Assumptions, and Limitations:
During this case study, we used two models: a linear model and a logistic model. The assumptions for the linear model include linearity, independence, homoscedasticity, and no multicollinearity. For the logistic model, the requirements are a binary dependent variable, independence of observations, linearity of the logit, no multicollinearity, and no perfect separation.


# Data:

*Discusses how data was handled, i.e. cleaned and preprocessed. Discusses distributions, correlations, etc.*

The dataset provided is well-structured, containing 21 variables related to client demographics and financial information, with a total of 4,119 observations. Although there are no *NA* values, we did notice a few columns containing 'Unknown' entries. In terms of variable types, we treated some as factors and others as numeric, as many of the original variables were labeled as characters. For instance, we converted *education* from a character to a factor and *emp.var.rate* from a character to numeric.

Add stuff for correlation

**Correlation**

```{r Correlation}
#| echo: false
# is there high correlation in any of our numeric variables
df_num <- dplyr::select_if(df1, is.numeric)
M = cor(df_num)
#looks like there is higher correlation between pdays and previous but it is under .6 
corrplot(M, method = c("color"))

```


Our dataset was unbalanced, with 3,668 records labeled as *No* and only 451 labeled as *Yes* in the y variable. To address this imbalance, we created a balanced dataset by splitting the data between the *Yes* and *No* labels and then sampling from each group. This resulted in a new dataset called *df_bal,* which contains an equal number of records. Balancing the data will help us train our model more effectively by ensuring that it doesn't become biased towards the majority class. This should improve the model's ability to accurately predict both outcomes and perform well across various metrics.

**Unbalanced Dataset**

```{r}
#| echo: false
summary(df1$y)

```

**Balanced Dataset**

```{r}
#| echo: false
summary(df_bal$y)
```

For our final dataset, we selected 19 variables initially. After applying backward elimination, we narrowed it down to 7 key variables for our final model. The variables we retained are: age, poutcome, campaign, cons.conf.idx, contact, cons.price.idx, and emp.var.rate.

# Results:

### Presents and discusses the results from model(s). Discusses relationships between covariates and response, if possible, and provides deep insights behind relationships in the context of the application.

Here we will be discussing the outputs from our two models we applied to the data set to best predict if a client will subscribe (yes/no) to a term deposit (y). We first begin with a simple linear model using all the variables we decided to select for our modeling. Here is the following output from our linear model.
