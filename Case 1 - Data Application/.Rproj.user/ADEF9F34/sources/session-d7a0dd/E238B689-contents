---
title: "Case Study 1"
author: "Alex Martinez"
date: "2024-09-10"
output: pdf_document
---

```{r libraries, include=FALSE}
#idk what i was going to use so i added everything that seemed useful
library(caret)
library(here)
library(lattice)
library(ggplot2)
library(logistf)
library(MASS)
library(tidyverse)
library(corrplot)
library(car)
```

####Created a template below and we can modify titles as progress####

# Executive Summary

Brief introduction of problem. Summarizes key findings. Summarizes insights behind key findings.

# Our Problem

Clear description of the problem, from an application and theoretical point of view. Outlines the report.

# Literature Review

Discusses and cites existing works in the theoretical and application realm.

# Methods

Discusses types of variables, sample size, and sampling techniques (if any). Discusses the model(s) and its assumptions and limitations.

# Data

Discusses how data was handled, i.e. cleaned and preprocessed. Discusses distributions, correlations, etc.

```{r Loading Data, warning=FALSE}
#df1 <- read.csv2("~/MS Data Applications/wk03 Bank Case Study/bank-additional.csv")

##### We can delete the path above once we confirm if works for you guys #####

#| echo: false
getwd() #open R project file to have the same file path
df1 = read.csv2('Data/bank-additional.csv') # Reading the csv from the location above

```

## Data Structure

```{r Data Structure}
str(df1) #Should we keep in final paper or hide?
```

## Data Cleanup

```{r Data Cleanup}
str(df1)
#change y into factor 
df1$y<-as.factor(df1$y)
df1$job<- as.factor(df1$job)
df1$marital <- as.factor(df1$marital)
df1$education <- as.factor(df1$education)
df1$default <- as.factor(df1$default)
df1$housing<- as.factor(df1$housing)
df1$loan <- as.factor(df1$loan)
df1$contact <- as.factor(df1$contact)
df1$month <- as.factor(df1$month)
df1$day_of_week <- as.factor(df1$day_of_week)
df1$poutcome <- as.factor(df1$poutcome)
df1$emp.var.rate <- as.numeric(df1$emp.var.rate)
df1$cons.price.idx <- as.numeric(df1$cons.price.idx)
df1$cons.conf.idx <- as.numeric(df1$cons.conf.idx)
df1$euribor3m <- as.numeric(df1$euribor3m)
df1$nr.employed <- as.integer(df1$nr.employed)
unique(df1$previous)
unique(df1$pdays)
df1$y_int <- ifelse(df1$y == 'yes', 1, 0)
df1$ppdays_ind <- ifelse(df1$pdays == 999, 0, 1)
df1$married_ind <- ifelse(df1$marital == 'married', 1, 0)


#Pdays - make it an indicator of not/yes
#duration - amt of time you have them, so same as Y 

```

# Results

Presents and discusses the results from model(s). Discusses relationships between covariates and response, if possible, and provides deep insights behind relationships in the context of the application.

# Conclusions

Concludes with a summary of the aim and results. Discusses alternative methods that can be used.

```{r}
#Exploring variables 




# is there high correlation in any of our numeric variables
df_num <- dplyr::select_if(df1, is.numeric)
M = cor(df_num)
#looks like there is higher correlation between pdays and previous but it is under .6 
corrplot(M, method = c("number"))

#data is unbalanced 3.6k no, 451 yes
summary(df1$y)
```




```{r model building}
#keep variables I want for Modeling
df2 <- df1 %>% select(age,job, married_ind, education, default, housing, loan, contact, campaign, 
                      ppdays_ind, previous, poutcome, emp.var.rate, cons.price.idx, cons.conf.idx, 
                      euribor3m, nr.employed, y, y_int) 


# since data is unbalanced we should take a more balanced sample
set.seed(42) 
df_y_y = df2 %>% filter(y == "yes")
df_y_n = df2 %>% filter(y == "no")
sample_y = sample_n(df_y_n, nrow(df_y_y))
df_bal = rbind(df_y_y,sample_y)

# test and train split

df_bal_split <- sample(nrow(df_bal),0.8*nrow(df_bal),replace = F) # Setting training sample to be 80% of the data
df_train <- df_bal[df_bal_split,]
df_test <- df_bal[-df_bal_split,]


# creating binary numeric variable for linear model
str(df2)

# first exploring with backwards step selection on lm with full data
lm1 <- lm(y_int ~ . -y, data = df_train)
summary(lm1)

lm1_step <- step(lm1, direction = "backward")
summary(lm1_step)

# final lm model base off of step 
lmf <- lm(y_int ~ age + contact + campaign + poutcome + emp.var.rate + 
    cons.price.idx + cons.conf.idx, data = df_train)
#summary(lmf)

vif(lmf) # confirm there is no co linearity 
# R- Squared is very small at 27% but is expectedc since y is binomial


### LETS TRY SAME TECHNIQUE BUT WITH LOGISTIC MODEL
#glm model
glm1 <- glm(y_int ~ . -y, data = df_train, family = binomial) #Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
summary(glm1)

# using backwards Step Selection
glm_step = step(glm1, direction = "backward") # stepwise backward elim.
summary(glm_step)

glmf <- glm(formula = y_int ~ age + contact + campaign + previous + poutcome + 
    emp.var.rate + cons.price.idx + cons.conf.idx, family = binomial, 
    data = df_train)
summary(glmf)

vif(glmf) # no colinearity detected

# Predict the probability on TEST - cutoff 0.5
df_test$PredProb <- predict.glm(glmf, newdata = df_test, type = 'response')

#create Prediction Indicators for y
df_test$Pred_Y <- ifelse(df_test$PredProb >= 0.5, 1, 0)

caret::confusionMatrix(as.factor(df_test$y_int),as.factor(df_test$Pred_Y), positive = '1') #this function and package auto computes a lot of the metrics
# accuracy: 74%
# sens: 80%
# Spec: 70%

plot(glmf)


##DETER4MINING BEST THRESHOLD FOR BEST SENSITIVITY
library(ROCR)
library(car)
library(tidyverse)
# Predict the probability (p) of x23strat
glmftest <- glm(formula = y_int ~ age + contact + campaign + previous + poutcome + 
    emp.var.rate + cons.price.idx + cons.conf.idx, family = binomial, 
    data = df_test)
probabilities <- predict(glmftest, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)

#### end of default cutoff of 0.5
#### optimal cutoff

#ROC Curve and AUC
pred <- prediction(probabilities,df_test$y_int) 
pred
#Predicted Probability and True Classification

# area under curve
auc <- round(as.numeric(performance(pred, measure = "auc")@y.values),3)
auc

#plotting the ROC curve and computing AUC
perf <- performance(pred, "tpr","fpr")
plot(perf,colorize = T, main = "ROC Curve")
text(0.5,0.5, paste("AUC:", auc))

# computing threshold for cutoff to best trade off sensitivity and specificity
#first sensitivity
plot(unlist(performance(pred, "sens")@x.values), unlist(performance(pred, "sens")@y.values), 
     type="l", lwd=2, 
     ylab="Sensitivity", xlab="Cutoff", main = paste("Maximized Cutoff\n","AUC: ",auc))

par(new=TRUE) # plot another line in same plot

#second specificity
plot(unlist(performance(pred, "spec")@x.values), unlist(performance(pred, "spec")@y.values), 
     type="l", lwd=2, col='red', ylab="", xlab="")
axis(4, at=seq(0,1,0.2)) #specificity axis labels
mtext("Specificity",side=4, col='red')

#find where the lines intersect
min.diff <-which.min(abs(unlist(performance(pred, "sens")@y.values) - unlist(performance(pred, "spec")@y.values)))
min.x<-unlist(performance(pred, "sens")@x.values)[min.diff]
min.y<-unlist(performance(pred, "spec")@y.values)[min.diff]
optimal <-min.x #this is the optimal points to best trade off sensitivity and specificity

abline(h = min.y, lty = 3)
abline(v = min.x, lty = 3)
text(min.x,0,paste("optimal threshold=",round(optimal,2)), pos = 3)





##OPTIMAL CUTOFF FOR BEST SENSITIVITY and specificity
#create Prediction Indicators for y
df_test$Pred_Y_best <- ifelse(df_test$PredProb >= 0.46, 1, 0)
caret::confusionMatrix(as.factor(df_test$y_int),as.factor(df_test$Pred_Y_best), positive = '1') #this function and package auto computes a lot of the metrics
# accuracy: 73%
# sens: 77%
# Spec: 70%


## best sensitivity
df_test$Pred_Y_sens <- ifelse(df_test$PredProb >= 0.3, 1, 0)
caret::confusionMatrix(as.factor(df_test$Pred_Y_sens), as.factor(df_test$y_int), positive = '1') #this function and package auto computes a lot of the metrics
# accuracy: 60%
# sens: 85%
# Spec: 34%



```
