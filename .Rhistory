min.x<-unlist(performance(pred, "sens")@x.values)[min.diff]
min.y<-unlist(performance(pred, "spec")@y.values)[min.diff]
optimal <-min.x #this is the optimal points to best trade off sensitivity and specificity
abline(h = min.y, lty = 3)
abline(v = min.x, lty = 3)
text(min.x,0,paste("optimal threshold=",round(optimal,2)), pos = 3)
##OPTIMAL CUTOFF FOR BEST SENSITIVITY and specificity
#create Prediction Indicators for y
df_test$Pred_Y_best <- ifelse(df_test$PredProb >= 0.46, 1, 0)
caret::confusionMatrix(as.factor(df_test$y_int),as.factor(df_test$Pred_Y_best), positive = '1') #this function and package auto computes a lot of the metrics
# accuracy: 73%
# sens: 77%
# Spec: 70%
#| echo: false
exp(coef(glmf)['age'])
exp(coef(glmf)['contacttelephone'])
exp(coef(glmf)['campaign            '])
exp(coef(glmf)['previous             '])
exp(coef(glmf)['poutcomenonexistent  '])
exp(coef(glmf)['poutcomesuccess      '])
exp(coef(glmf)['emp.var.rate'])
exp(coef(glmf)['cons.price.idx'])
exp(coef(glmf)['cons.conf.idx'])
#| echo: false
par(mfrow=c(1,1), mar=c(1, 1, 1, 1), pin=c(4, 4))  # Adjust pin to control plot size
df_num <- dplyr::select_if(df1, is.numeric)
M = cor(df_num)
corrplot(M, method = "color")
#| echo: false
par(mfrow=c(1,1), mar=c(1, 1, 1, 1), pin=c(3, 3))  # Adjust pin to control plot size
df_num <- dplyr::select_if(df1, is.numeric)
M = cor(df_num)
corrplot(M, method = "color")
#| echo: false
par(mfrow=c(1,1), mar=c(.5, .5, .5, .5), pin=c(3, 3))  # Adjust pin to control plot size
df_num <- dplyr::select_if(df1, is.numeric)
M = cor(df_num)
corrplot(M, method = "color")
dow_data = read.csv('Data/dow_jones_index.data') # change variable name to match code
View(dow_data)
dow_names = read.csv('Data/dow_jones_index.names')  # change variable name to match code
View(dow_names)
library(dplyr)
library(ggplot2)
library(tree)
library(dplyr)
library(ggplot2)
intsall.library("tree")
library(dplyr)
library(ggplot2)
install.packages("tree")
library(tree)
library(ISLR)
#getwd() #open R project file to have the same file path
dow_data = read.csv('Data/dow_jones_index.data') # change variable name to match code
#dow_names = read.csv('Data/dow_jones_index.names')  # change variable name to match code
## Taking the $ sign off
dow_data <- dow_data %>%
mutate(open = as.numeric(gsub("\\$", "", open)),
high = as.numeric(gsub("\\$", "", high)),
low = as.numeric(gsub("\\$", "", low)),
next_weeks_open = as.numeric(gsub("\\$", "", next_weeks_open)),
next_weeks_close = as.numeric(gsub("\\$", "", next_weeks_close)),
close = as.numeric(gsub("\\$", "", close)))
## remove missing values
dow_data <- na.omit(dow_data)
dow_data$Positive_percent_change_ind <- factor(ifelse(dow_data$percent_change_next_weeks_price > 0, "1", "0"))
## Splitting data based on PDF
train = dow_data %>%
filter(quarter == 1) %>%
select(-percent_change_next_weeks_price, -quarter, -date)
test = dow_data %>%
filter(quarter == 2) %>%
select(-percent_change_next_weeks_price, -quarter, -date)
## grow tree
Stock_tree <- tree(Positive_percent_change_ind ~ ., data = train)
## default output
Stock_tree
## result summary
summary(Stock_tree)
## plot tree
plot(Stock_tree)
text(Stock_tree, cex = 0.55)
# Evaluating
pred <- predict(Stock_tree, newdata = test, type = "class")
# accuarcy
table(pred, test$Positive_percent_change_ind)
set.seed(11)
cv_tree <- cv.tree(Stock_tree, FUN = prune.misclass)
cv_tree
# plot the estimated error from cross-validation
par(mfrow = c(1,2))
plot(cv_tree$size, cv_tree$dev, type = "b")
plot(cv_tree$k, cv_tree$dev, type = "b")
# best tree with smallest k (small prune, and tree size is large)
best_size <- cv_tree$size[which.min(cv_tree$dev)]
# building prune model
prune_tree <- prune.misclass(Stock_tree, best = best_size)
# plot prune tree
plot(prune_tree)
text(prune_tree, cex = .55)
# get predictions
pred_prune <- predict(prune_tree, newdata = test, type = "class")
#check accuracy
table(pred_prune, test$Positive_percent_change_ind)
summary(dow_data)
str(dow_data)
colSums(is.na(dow_data))
unique(dow_data$stock)
#{{< pagebreak >}}
install.packages("SMCRM")
library(SMCRM)
install.packages("SMCRM")
library(SMCRM)
data("acquisitionRetention")
df <- acquisitionRetention
head(df)
summary(df)
df$customer <- NULL
summary(df)
sum(is.na(df))
install.packages("PerformanceAnalytics")
install.packages("SMCRM")
library(PerformanceAnalytics)
chart.Correlation(df, histogram = TRUE, pch=19)
par(mfrow=c(3,3))
boxplot(duration ~ acquisition, data=df, ylab='duration', xlab='acquisition', col='#FF0000')
boxplot(profit ~ acquisition, data=df, ylab='profit', xlab='acquisition', col='#FF3300')
boxplot(ret_exp ~ acquisition, data=df, ylab='ret_exp', xlab='acquisition', col='#CC9933')
boxplot(acq_exp_sq ~ acquisition, data=df, ylab='acq_exp_sq', xlab='acquisition', col='#33CC00')
boxplot(ret_exp_sq ~ acquisition, data=df, ylab='ret_exp_sq', xlab='acquisition', col='#99CCFF')
boxplot(freq ~ acquisition, data=df, ylab='freq', xlab='acquisition', col='#0000CC')
boxplot(freq_sq ~ acquisition, data=df, ylab='freq_sq', xlab='acquisition', col='#9933CC')
boxplot(crossbuy ~ acquisition, data=df, ylab='crossbuy', xlab='acquisition', col='#9900FF')
boxplot(sow ~ acquisition, data=df, ylab='sow', xlab='acquisition', col='#6600FF')
par(mfrow=c(1,1))
df$acquisition <- as.factor(df$acquisition)
df$industry <- as.factor(df$industry)
summary(df)
library(caret)
set.seed(1)
TrnCtrl <- trainControl(method = 'repeatedcv', number = 10, repeats = 2)
set.seed(1)
inTrain <- createDataPartition(y = df$acquisition, p=0.8, list=FALSE)
df.train <- df[inTrain, ]
df.test <- df[-inTrain, ]
set.seed(1)
RF1 <- train(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, method='rf', trControl = TrnCtrl, importance=TRUE)
#RF1$finalModel
RF1acq.preds <- predict(RF1, df.test)
confusionMatrix(RF1acq.preds, df.test$acquisition)
RF1acq.preds.full <- predict(RF1, df)
df2 <- cbind(df, RF1acq.preds.full)
df3 <- subset(df2, RF1acq.preds.full == "1" & acquisition == "1")
#Let's take a look at the new dataset
summary(df3)
chart.Correlation(df3[ ,c(2:5,8,10,11,13,14)], histogram=TRUE, pch=19)
install.packages("car")
library(car)
set.seed(1)
glm.viftest <- glm(duration ~ profit + acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3)
vif(glm.viftest)
set.seed(1)
glm.viftest <- glm(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3)
vif(glm.viftest)
install.packages("randomForestSRC")
library(randomForestSRC)
set.seed(1)
tuner <- expand.grid(mtry = c(1:10))
RF2 <- rfsrc(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3, tuneGrid = tuner, importance = TRUE, ntree = 1000)
#gather up the predicted durations based on the RF2 regression model
duration.preds <- predict(RF2, df3)$predicted
#roll the duration.preds into ANOTHER dataframe
df4 <- cbind(df3, duration.preds)
mean.actual.duration <- mean(df4$duration)
mean.predicted.duration <- mean(df4$duration.preds)
median.actual.duration <- median(df4$duration)
median.predicted.duration <- median(df4$duration.preds)
#sum.actual.duration <- sum(df4$duration) #Probably not necessary, commenting out
#sum.predicted.duration <- sum(df4$duration.preds) #Probably not necessary, commenting out
cat('Mean of actual duration: ', mean.actual.duration)
cat('\nMean of predicted duration: ', mean.predicted.duration)
cat('\n\nMedian of actual duration: ', median.actual.duration)
cat('\nMedian of predicted duration: ', median.predicted.duration)
var.imp <- RF2$importance
var.imp
install.packages("jtools")
library(jtools)
data.frame(importance = RF2$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "orange", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")+
theme_nice()
install.packages("jtools")
library(jtools)
data.frame(importance = RF2$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "orange", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")+
theme_nice()
install.packages("jtools")
install.packages("jtools")
library(jtools)
data.frame(importance = RF2$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "orange", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")+
theme_nice()
install.packages("jtools")
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
chart.Correlation(df, histogram = TRUE, pch=19)
install.packages("PerformanceAnalytics")
data("acquisitionRetention")
df <- acquisitionRetention
head(df)
summary(df)
df$customer <- NULL
summary(df)
sum(is.na(df))
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
chart.Correlation(df, histogram = TRUE, pch=19)
install.packages("PerformanceAnalytics")
par(mfrow=c(3,3))
boxplot(duration ~ acquisition, data=df, ylab='duration', xlab='acquisition', col='#FF0000')
boxplot(profit ~ acquisition, data=df, ylab='profit', xlab='acquisition', col='#FF3300')
boxplot(ret_exp ~ acquisition, data=df, ylab='ret_exp', xlab='acquisition', col='#CC9933')
boxplot(acq_exp_sq ~ acquisition, data=df, ylab='acq_exp_sq', xlab='acquisition', col='#33CC00')
boxplot(ret_exp_sq ~ acquisition, data=df, ylab='ret_exp_sq', xlab='acquisition', col='#99CCFF')
boxplot(freq ~ acquisition, data=df, ylab='freq', xlab='acquisition', col='#0000CC')
boxplot(freq_sq ~ acquisition, data=df, ylab='freq_sq', xlab='acquisition', col='#9933CC')
boxplot(crossbuy ~ acquisition, data=df, ylab='crossbuy', xlab='acquisition', col='#9900FF')
boxplot(sow ~ acquisition, data=df, ylab='sow', xlab='acquisition', col='#6600FF')
par(mfrow=c(1,1))
df$acquisition <- as.factor(df$acquisition)
df$industry <- as.factor(df$industry)
summary(df)
library(caret)
set.seed(1)
TrnCtrl <- trainControl(method = 'repeatedcv', number = 10, repeats = 2)
set.seed(1)
inTrain <- createDataPartition(y = df$acquisition, p=0.8, list=FALSE)
df.train <- df[inTrain, ]
df.test <- df[-inTrain, ]
set.seed(1)
RF1 <- train(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, method='rf', trControl = TrnCtrl, importance=TRUE)
#RF1$finalModel
RF1acq.preds <- predict(RF1, df.test)
confusionMatrix(RF1acq.preds, df.test$acquisition)
library(caret)
set.seed(1)
TrnCtrl <- trainControl(method = 'repeatedcv', number = 10, repeats = 2)
set.seed(1)
inTrain <- createDataPartition(y = df$acquisition, p=0.8, list=FALSE)
df.train <- df[inTrain, ]
df.test <- df[-inTrain, ]
set.seed(1)
RF1 <- train(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, method='rf', trControl = TrnCtrl, importance=TRUE)
#RF1$finalModel
RF1acq.preds <- predict(RF1, df.test)
confusionMatrix(RF1acq.preds, df.test$acquisition)
par(mfrow=c(1,1))
df$acquisition <- as.factor(df$acquisition)
df$industry <- as.factor(df$industry)
summary(df)
library(caret)
set.seed(1)
TrnCtrl <- trainControl(method = 'repeatedcv', number = 10, repeats = 2)
set.seed(1)
inTrain <- createDataPartition(y = df$acquisition, p=0.8, list=FALSE)
df.train <- df[inTrain, ]
df.test <- df[-inTrain, ]
set.seed(1)
RF1 <- train(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, method='rf', trControl = TrnCtrl, importance=TRUE)
#RF1$finalModel
RF1acq.preds <- predict(RF1, df.test)
confusionMatrix(RF1acq.preds, df.test$acquisition)
install.packages("jtools")
library(jtools)
data.frame(importance = RF2$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "orange", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")+
theme_nice()
install.packages("jtools")
install.packages("car")
library(car)
set.seed(1)
glm.viftest <- glm(duration ~ profit + acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3)
vif(glm.viftest)
install.packages("car")
set.seed(1)
glm.viftest <- glm(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3)
vif(glm.viftest)
install.packages("randomForestSRC")
library(randomForestSRC)
set.seed(1)
tuner <- expand.grid(mtry = c(1:10))
RF2 <- rfsrc(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3, tuneGrid = tuner, importance = TRUE, ntree = 1000)
#gather up the predicted durations based on the RF2 regression model
duration.preds <- predict(RF2, df3)$predicted
#roll the duration.preds into ANOTHER dataframe
df4 <- cbind(df3, duration.preds)
install.packages("randomForestSRC")
install.packages("randomForestSRC")
library(randomForestSRC)
set.seed(1)
tuner <- expand.grid(mtry = c(1:10))
RF2 <- rfsrc(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3, tuneGrid = tuner, importance = TRUE, ntree = 1000)
#gather up the predicted durations based on the RF2 regression model
duration.preds <- predict(RF2, df3)$predicted
#roll the duration.preds into ANOTHER dataframe
df4 <- cbind(df3, duration.preds)
install.packages("randomForestSRC")
mean.actual.duration <- mean(df4$duration)
mean.predicted.duration <- mean(df4$duration.preds)
median.actual.duration <- median(df4$duration)
median.predicted.duration <- median(df4$duration.preds)
#sum.actual.duration <- sum(df4$duration) #Probably not necessary, commenting out
#sum.predicted.duration <- sum(df4$duration.preds) #Probably not necessary, commenting out
cat('Mean of actual duration: ', mean.actual.duration)
cat('\nMean of predicted duration: ', mean.predicted.duration)
cat('\n\nMedian of actual duration: ', median.actual.duration)
cat('\nMedian of predicted duration: ', median.predicted.duration)
var.imp <- RF2$importance
var.imp
install.packages("jtools")
library(jtools)
data.frame(importance = RF2$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "orange", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")+
theme_nice()
install.packages("jtools")
log.var.imp <- log(var.imp + 200)
log.var.imp
data.frame(importance = log.var.imp) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "orange", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")+
theme_nice()
mindepth <- max.subtree(RF2, sub.order = TRUE)
print(round(mindepth$order, 3)[,1])
data.frame(importance = log.var.imp) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "orange", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")+
theme_nice()
install.packages("jtools")
library(jtools)
data.frame(importance = RF2$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "orange", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")+
theme_nice()
install.packages("jtools")
data.frame(md = round(mindepth$order, 3)[,1]) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,desc(md)), y = md)) +
geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.2)+
coord_flip() +
labs(x = "Variables", y = "Minimal Depth")+
theme_nice()
mindepth$sub.order
as.matrix(mindepth$sub.order) %>%
reshape2::melt() %>%
data.frame() %>%
ggplot(aes(x = Var1, y = Var2, fill = value)) +
scale_x_discrete(position = "top") +
geom_tile(color = "white") +
viridis::scale_fill_viridis("Relative min. depth") +
labs(x = "Model Variables", y = "Model Variables") +
theme_bw()
find.interaction(RF2, method = "vimp", importance = "permute")
set.seed(1)
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(2,6,1)
nodesize.values <- seq(2,8,2)
ntree.values <- seq(1e3,6e3,500)
# Create a data frame containing all combinations
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)
# Create an empty vector to store OOB error values
oob_err <- c()
# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {
# Train a Random Forest model
model <- rfsrc(duration ~ acq_exp +
ret_exp +
freq +
crossbuy +
sow +
industry +
revenue +
employees,
data = df3,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i],
ntree = hyper_grid$ntree[i])
# Store OOB error for the model
oob_err[i] <- model$err.rate[length(model$err.rate)]
}
# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
print(hyper_grid[opt_i,])
set.seed(1)
RF2.tuned <- rfsrc(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df4, mtry = 6, nodesize = 2, ntree = 2500, importance = TRUE)
#gather up the predicted durations based on the RF2.tuned regression model
duration.preds.tuned <- predict(RF2.tuned, df4)$predicted
#roll the duration.preds into yet ANOTHER dataframe, df5 this time, for the tuned model
df5 <- cbind(df4, duration.preds.tuned)
#Now let us compare the performance of the standard vs. tuned random forest regression predictions
#compare the mean values
mean.actual.duration <- mean(df5$duration)
mean.predicted.duration <- mean(df5$duration.preds)
mean.predicted.duration.tuned <- mean(df5$duration.preds.tuned)
#compare the median values
median.actual.duration <- median(df5$duration)
median.predicted.duration <- median(df5$duration.preds)
median.predicted.duration.tuned <- median(df5$duration.preds.tuned)
#compare the MSE values
MSE.predicted.duration <- mean((df5$duration.preds - df5$duration)^2)
MSE.predicted.duration.tuned <- mean((df5$duration.preds.tuned - df5$duration)^2)
cat('Mean of actual duration: ', mean.actual.duration)
cat('\nMean of predicted duration: ', mean.predicted.duration)
find.interaction(RF2, method = "vimp", importance = "permute")
set.seed(1)
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(2,6,1)
nodesize.values <- seq(2,8,2)
ntree.values <- seq(1e3,6e3,500)
# Create a data frame containing all combinations
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)
# Create an empty vector to store OOB error values
oob_err <- c()
# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {
# Train a Random Forest model
model <- rfsrc(duration ~ acq_exp +
ret_exp +
freq +
crossbuy +
sow +
industry +
revenue +
employees,
data = df3,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i],
ntree = hyper_grid$ntree[i])
# Store OOB error for the model
oob_err[i] <- model$err.rate[length(model$err.rate)]
}
install.packages("SMCRM")
library(SMCRM)
data("acquisitionRetention")
df <- acquisitionRetention
head(df)
summary(df)
df$customer <- NULL
summary(df)
sum(is.na(df))
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
chart.Correlation(df, histogram = TRUE, pch=19)
par(mfrow=c(1,1))
df$acquisition <- as.factor(df$acquisition)
df$industry <- as.factor(df$industry)
summary(df)
library(caret)
set.seed(1)
TrnCtrl <- trainControl(method = 'repeatedcv', number = 10, repeats = 2)
set.seed(1)
inTrain <- createDataPartition(y = df$acquisition, p=0.8, list=FALSE)
df.train <- df[inTrain, ]
df.test <- df[-inTrain, ]
set.seed(1)
RF1 <- train(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, method='rf', trControl = TrnCtrl, importance=TRUE)
#RF1$finalModel
RF1acq.preds <- predict(RF1, df.test)
confusionMatrix(RF1acq.preds, df.test$acquisition)
RF1acq.preds.full <- predict(RF1, df)
df2 <- cbind(df, RF1acq.preds.full)
df3 <- subset(df2, RF1acq.preds.full == "1" & acquisition == "1")
#Let's take a look at the new dataset
summary(df3)
chart.Correlation(df3[ ,c(2:5,8,10,11,13,14)], histogram=TRUE, pch=19)
install.packages("car")
library(car)
set.seed(1)
glm.viftest <- glm(duration ~ profit + acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3)
vif(glm.viftest)
set.seed(1)
glm.viftest <- glm(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3)
vif(glm.viftest)
update.packages(ask = FALSE)
