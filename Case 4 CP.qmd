---
title: "CaseStudy4"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
1 + 1
```

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

```{r}

install.packages("SMCRM")
library(SMCRM)
```

```{r}

data("acquisitionRetention")

df <- acquisitionRetention

head(df)
```

```{r}
 summary(df)
```

```{r}

df$customer <- NULL
```

```{r}

summary(df)

```

```{r}

sum(is.na(df))
```

```{r}
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
chart.Correlation(df, histogram = TRUE, pch=19)
```

```{r}

par(mfrow=c(3,3))
boxplot(duration ~ acquisition, data=df, ylab='duration', xlab='acquisition', col='#FF0000')
boxplot(profit ~ acquisition, data=df, ylab='profit', xlab='acquisition', col='#FF3300')
boxplot(ret_exp ~ acquisition, data=df, ylab='ret_exp', xlab='acquisition', col='#CC9933')
boxplot(acq_exp_sq ~ acquisition, data=df, ylab='acq_exp_sq', xlab='acquisition', col='#33CC00')
boxplot(ret_exp_sq ~ acquisition, data=df, ylab='ret_exp_sq', xlab='acquisition', col='#99CCFF')
boxplot(freq ~ acquisition, data=df, ylab='freq', xlab='acquisition', col='#0000CC')
boxplot(freq_sq ~ acquisition, data=df, ylab='freq_sq', xlab='acquisition', col='#9933CC')
boxplot(crossbuy ~ acquisition, data=df, ylab='crossbuy', xlab='acquisition', col='#9900FF')
boxplot(sow ~ acquisition, data=df, ylab='sow', xlab='acquisition', col='#6600FF')
```

```{r}

par(mfrow=c(1,1))
df$acquisition <- as.factor(df$acquisition)
df$industry <- as.factor(df$industry)
```

```{r}

summary(df)
```

```{r}

library(caret)
```

```{r}

set.seed(1)

TrnCtrl <- trainControl(method = 'repeatedcv', number = 10, repeats = 2)
```

```{r}

set.seed(1)
inTrain <- createDataPartition(y = df$acquisition, p=0.8, list=FALSE)
df.train <- df[inTrain, ]
df.test <- df[-inTrain, ]
```

```{r}

set.seed(1)
RF1 <- train(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, method='rf', trControl = TrnCtrl, importance=TRUE)
#RF1$finalModel

RF1acq.preds <- predict(RF1, df.test)
confusionMatrix(RF1acq.preds, df.test$acquisition)
```

```         
```

```{r}

RF1acq.preds.full <- predict(RF1, df)

```

```{r}
df2 <- cbind(df, RF1acq.preds.full)
```

```{r}

df3 <- subset(df2, RF1acq.preds.full == "1" & acquisition == "1")
#Let's take a look at the new dataset
summary(df3)
```

```{r}

chart.Correlation(df3[ ,c(2:5,8,10,11,13,14)], histogram=TRUE, pch=19)
```

```{r}
install.packages("car")
library(car)

set.seed(1)
glm.viftest <- glm(duration ~ profit + acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3)
vif(glm.viftest)
```

```{r}

set.seed(1)
glm.viftest <- glm(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3)
vif(glm.viftest)
```

```{r}

install.packages("randomForestSRC")


library(randomForestSRC)

set.seed(1)

tuner <- expand.grid(mtry = c(1:10))

RF2 <- rfsrc(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df3, tuneGrid = tuner, importance = TRUE, ntree = 1000)
#gather up the predicted durations based on the RF2 regression model
duration.preds <- predict(RF2, df3)$predicted
#roll the duration.preds into ANOTHER dataframe
df4 <- cbind(df3, duration.preds)
```

```{r}

mean.actual.duration <- mean(df4$duration)
mean.predicted.duration <- mean(df4$duration.preds)

median.actual.duration <- median(df4$duration)
median.predicted.duration <- median(df4$duration.preds)

#sum.actual.duration <- sum(df4$duration) #Probably not necessary, commenting out
#sum.predicted.duration <- sum(df4$duration.preds) #Probably not necessary, commenting out

cat('Mean of actual duration: ', mean.actual.duration)
```

```{r}

cat('\nMean of predicted duration: ', mean.predicted.duration)
```

```{r}

cat('\n\nMedian of actual duration: ', median.actual.duration)
```

```{r}

cat('\nMedian of predicted duration: ', median.predicted.duration)
```

```         
```

```{r}

var.imp <- RF2$importance
var.imp
```

```{r}

install.packages("jtools")
library(jtools)

data.frame(importance = RF2$importance) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black")+
    coord_flip() +
     labs(x = "Variables", y = "Variable importance")+
     theme_nice()
```

```{r}

log.var.imp <- log(var.imp + 200)
log.var.imp
```

```{r}

data.frame(importance = log.var.imp) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black")+
    coord_flip() +
     labs(x = "Variables", y = "Variable importance")+
     theme_nice()
```

```{r}

mindepth <- max.subtree(RF2, sub.order = TRUE)
print(round(mindepth$order, 3)[,1])
```

```{r}

data.frame(md = round(mindepth$order, 3)[,1]) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,desc(md)), y = md)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.2)+
    coord_flip() +
     labs(x = "Variables", y = "Minimal Depth")+
     theme_nice()
```

```{r}

mindepth$sub.order
```

```{r}

as.matrix(mindepth$sub.order) %>%
  reshape2::melt() %>%
  data.frame() %>%
  ggplot(aes(x = Var1, y = Var2, fill = value)) +
    scale_x_discrete(position = "top") +
    geom_tile(color = "white") +
    viridis::scale_fill_viridis("Relative min. depth") +
    labs(x = "Model Variables", y = "Model Variables") +
    theme_bw()
```

```{r}

find.interaction(RF2, method = "vimp", importance = "permute")
```

```{r}

set.seed(1)
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(2,6,1)
nodesize.values <- seq(2,8,2)
ntree.values <- seq(1e3,6e3,500)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
   model <- rfsrc(duration ~ acq_exp +
                    ret_exp +
                    freq +
                    crossbuy +
                    sow +
                    industry +
                    revenue +
                    employees,
                    data = df3,
                    mtry = hyper_grid$mtry[i],
                    nodesize = hyper_grid$nodesize[i],
                    ntree = hyper_grid$ntree[i])  
  
                          
    # Store OOB error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
print(hyper_grid[opt_i,])
```

```{r}
set.seed(1)

RF2.tuned <- rfsrc(duration ~ acq_exp + ret_exp + freq + crossbuy + sow + industry + revenue + employees, data = df4, mtry = 6, nodesize = 2, ntree = 2500, importance = TRUE)
#gather up the predicted durations based on the RF2.tuned regression model
duration.preds.tuned <- predict(RF2.tuned, df4)$predicted
#roll the duration.preds into yet ANOTHER dataframe, df5 this time, for the tuned model
df5 <- cbind(df4, duration.preds.tuned)

#Now let us compare the performance of the standard vs. tuned random forest regression predictions

#compare the mean values
mean.actual.duration <- mean(df5$duration)
mean.predicted.duration <- mean(df5$duration.preds)
mean.predicted.duration.tuned <- mean(df5$duration.preds.tuned)

#compare the median values
median.actual.duration <- median(df5$duration)
median.predicted.duration <- median(df5$duration.preds)
median.predicted.duration.tuned <- median(df5$duration.preds.tuned)

#compare the MSE values
MSE.predicted.duration <- mean((df5$duration.preds - df5$duration)^2)
MSE.predicted.duration.tuned <- mean((df5$duration.preds.tuned - df5$duration)^2)

cat('Mean of actual duration: ', mean.actual.duration)

```

```{r}

cat('\nMean of predicted duration: ', mean.predicted.duration)
```

```{r}

cat('\nMean of tuned predicted duration: ', mean.predicted.duration.tuned)
```

```{r}

cat('\n\nMedian of actual duration: ', median.actual.duration)
```

```{r}

cat('\nMedian of predicted duration: ', median.predicted.duration)
```

```{r}

cat('\nMedian of tuned predicted duration: ', median.predicted.duration.tuned)
```

```{r}

cat('\n\nMSE un-tuned random forest: ', MSE.predicted.duration)
```

```{r}

cat('\nMSE tuned random forest: ', MSE.predicted.duration.tuned)
```

```{r}

set.seed(1)
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(2,6,1)
nodesize.values <- seq(2,8,2)
ntree.values <- seq(1e3,6e3,500)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
   model <- rfsrc(acquisition ~ acq_exp +
                    industry +
                    revenue +
                    employees,
                    data = df.train,
                    mtry = hyper_grid$mtry[i],
                    nodesize = hyper_grid$nodesize[i],
                    ntree = hyper_grid$ntree[i])  
  
                          
    # Store OOB error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
print(hyper_grid[opt_i,])
```

```{r}

RF1.tuned <- rfsrc(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, mtry = 2, nodesize = 4, ntree = 1000, importance = TRUE)
#gather up the predicted durations based on the RF1.tuned regression model
RF1acq.preds.tuned <- predict(RF1.tuned, df.test)$class

#Create a basic confusion matrix for the RF1 model
RF1.confusion <- table(RF1acq.preds, df.test$acquisition)
#Create a basic confusion matrix for the tuned RF1 model
RF1.confusion.tuned <- table(RF1acq.preds.tuned, df.test$acquisition)
```

```{r}

set.seed(1)

#Decision tree is first, and I am doing all of this in CARET using the same trainControl argument throughout
DT <- train(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, method='rpart', trControl = TrnCtrl)
DT.preds <- predict(DT, df.test)
DT.confusion <- table(DT.preds, df.test$acquisition)

#LOGIT model is next, also done in CARET
GLM <- train(acquisition ~ acq_exp + industry + revenue + employees, data = df.train, method='glm', family='binomial', trControl = TrnCtrl)
GLM.preds <- predict(GLM, df.test)
GLM.confusion <- table(GLM.preds, df.test$acquisition)

#I gather up the information from the various confusion matrixes
RF1.accuracy.tuned <- sum(diag(RF1.confusion.tuned))/sum(RF1.confusion.tuned)
RF1.accuracy <- sum(diag(RF1.confusion))/sum(RF1.confusion)
DT.accuracy <- sum(diag(DT.confusion))/sum(DT.confusion)
GLM.accuracy <- sum(diag(GLM.confusion))/sum(GLM.confusion)

#Print out the accuracies
cat('Accuracy of Original Classification Random Forest: ', RF1.accuracy)
```

```{r}

cat('\nAccuracy of Tuned Classification Random Forest: ', RF1.accuracy.tuned)
```

```{r}
cat('\nAccuacy of Decision Tree Model: ', DT.accuracy)
```

```{r}
cat('\nAccuracy of LOGIT Classification Model: ', GLM.accuracy)
```

```{r}

GLM.confusion
```

```{r}

DT.confusion
```

```{r}

RF1.confusion
```

```{r}

RF1.confusion.tuned
```

```{r}

install.packages("rattle")
library(rattle)

rattle::fancyRpartPlot(DT$finalModel, sub = "Decision Tree for Predicting Acquisition")
```

```{r}

summary(GLM)
```

```{r}

plot.variable(RF1.tuned, partial=TRUE)
```

```{r}

plot.variable(RF2.tuned, partial = TRUE)
```
